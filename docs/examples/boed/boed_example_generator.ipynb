{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd371a71e6e8979",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bayesian optimal experimental design\n",
    "This notebook implements Bayesian optimal experimental design (BOED) using the statistical programming package pyro. Based on the example shown in https://pyro.ai/examples/working_memory.html.\n",
    "\n",
    "In this case we aim to sample points in $x$ that will provide the most information about the model parameters $x_0$,$w$,$b$ of the function $f$ below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:37:28.196766700Z",
     "start_time": "2024-08-31T03:37:26.359068400Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# define the function\n",
    "def f(x, x0, d, b):\n",
    "    x = x - x0\n",
    "    return -d * 0.5 * (1 + torch.tanh(x / b))\n",
    "\n",
    "# define a noise corrupted version of the function\n",
    "def f_noisy(x, x0, d, b, noise_std=0.01):\n",
    "    return f(x, x0, d, b) + torch.randn_like(x) * noise_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc806f377413e1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:37:28.331949100Z",
     "start_time": "2024-08-31T03:37:28.196766700Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualize the ground truth function\n",
    "ground_truth_x0 = 2.0 # lower edge location\n",
    "ground_truth_d = 1 # plateau height\n",
    "ground_truth_b = 0.1 # sharpness of the plateau edge\n",
    "test_x = torch.linspace(0,3,100)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(test_x,f_noisy(\n",
    "    test_x,    \n",
    "    x0=ground_truth_x0,\n",
    "    d=ground_truth_d,\n",
    "    b=ground_truth_b\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7de139940e77c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:37:28.574566100Z",
     "start_time": "2024-08-31T03:37:28.340290500Z"
    }
   },
   "outputs": [],
   "source": [
    "from xopt import Xopt, VOCS, Evaluator\n",
    "from xopt.generators.bayesian.boed import BOEDGenerator\n",
    "from xopt.numerical_optimizer import GridOptimizer\n",
    "import pyro.distributions as dist\n",
    "\n",
    "vocs = VOCS(\n",
    "    variables={\"x\": [0.0, 3.0]},\n",
    "    observables=[\"y\"]\n",
    ")\n",
    "priors = {\n",
    "    \"x0\": dist.Normal(2.0, 1.0),\n",
    "    \"d\": dist.Normal(1.0, 0.5),\n",
    "    \"b\": dist.Normal(0.1, 0.01)\n",
    "}\n",
    "generator = BOEDGenerator(\n",
    "    vocs=vocs,\n",
    "    model_priors=priors,\n",
    "    measurement_noise=0.01,\n",
    "    model_function=f,\n",
    "    numerical_optimizer=GridOptimizer(n_grid_points=1000),\n",
    "    train_steps=3000,\n",
    "    train_lr=0.01\n",
    ")\n",
    "\n",
    "evaluator = Evaluator(\n",
    "    function=lambda x: {\"y\": float(f_noisy(torch.tensor(x[\"x\"]), ground_truth_x0, ground_truth_d, ground_truth_b))}\n",
    ")\n",
    "\n",
    "X = Xopt(\n",
    "    vocs=vocs,\n",
    "    generator=generator,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "\n",
    "X.grid_evaluate(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ece11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.generator.train_model(X.data)\n",
    "predictive = X.generator.get_predictive()\n",
    "\n",
    "test_x = torch.linspace(0,3,100)\n",
    "pred = predictive(test_x)\n",
    "y = pred[\"y\"]\n",
    "\n",
    "print(y.shape)\n",
    "print(pred.keys())\n",
    "\n",
    "# plot the predictions\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(test_x.numpy(), y.quantile(0.5, dim=0).numpy())\n",
    "l = y.quantile(0.05, dim=0).numpy()\n",
    "u = y.quantile(0.95, dim=0).numpy()\n",
    "\n",
    "ax.fill_between(test_x.numpy(),l,u,alpha=0.3)\n",
    "ax.scatter(X.data[\"x\"], X.data[\"y\"], color=\"red\")\n",
    "\n",
    "# overlay a few samples from the learned model\n",
    "for i in range(10):\n",
    "    ax.plot(test_x.numpy(), y[i].numpy(), color=\"gray\", alpha=0.15)\n",
    "\n",
    "# plot the eig\n",
    "#X.generator.visualize_model()\n",
    "\n",
    "current_model = X.generator.model\n",
    "acqf = X.generator._get_acquisition(current_model)\n",
    "candidate_designs = torch.linspace(0, 3, 1000).unsqueeze(-1)\n",
    "eig = acqf(candidate_designs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(candidate_designs.numpy(), eig.detach().numpy())\n",
    "\n",
    "fig, ax = plt.subplots(1,len(priors.keys()), figsize=(15,5))\n",
    "for i, (name, prior) in enumerate(priors.items()):\n",
    "    h, bins = torch.histogram(pred[name], bins=30, density=True)\n",
    "    width = (bins[1]-bins[0]).numpy()\n",
    "    ax[i].bar(bins[:-1].numpy(), h.numpy(), width=width, alpha=0.5, label=\"Posterior\")\n",
    "    \n",
    "    ax[i].plot(bins.numpy(), torch.exp(prior.log_prob(bins)).numpy(), \"r\", label=\"Prior\")\n",
    "    ax[i].set_title(name)\n",
    "    ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(i)\n",
    "    X.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6dde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b054a561d91b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-31T03:39:47.437470200Z",
     "start_time": "2024-08-31T03:39:47.288621400Z"
    }
   },
   "outputs": [],
   "source": [
    "X.generator.train_model(X.data)\n",
    "predictive = X.generator.get_predictive()\n",
    "\n",
    "test_x = torch.linspace(0,3,100)\n",
    "pred = predictive(test_x)\n",
    "y = pred[\"y\"]\n",
    "\n",
    "print(y.shape)\n",
    "print(pred.keys())\n",
    "\n",
    "# plot the predictions\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(test_x.numpy(), y.quantile(0.5, dim=0).numpy())\n",
    "l = y.quantile(0.05, dim=0).numpy()\n",
    "u = y.quantile(0.95, dim=0).numpy()\n",
    "\n",
    "ax.fill_between(test_x.numpy(),l,u,alpha=0.3)\n",
    "ax.scatter(X.data[\"x\"], X.data[\"y\"], color=\"red\")\n",
    "\n",
    "# overlay a few samples from the learned model\n",
    "for i in range(10):\n",
    "    ax.plot(test_x.numpy(), y[i].numpy(), color=\"gray\", alpha=0.15)\n",
    "\n",
    "# plot the eig\n",
    "#X.generator.visualize_model()\n",
    "\n",
    "current_model = X.generator.model\n",
    "acqf = X.generator._get_acquisition(current_model)\n",
    "candidate_designs = torch.linspace(0, 3, 1000).unsqueeze(-1)\n",
    "eig = acqf(candidate_designs)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(candidate_designs.numpy(), eig.detach().numpy())\n",
    "\n",
    "fig, ax = plt.subplots(1,len(priors.keys()), figsize=(15,5))\n",
    "for i, (name, prior) in enumerate(priors.items()):\n",
    "    h, bins = torch.histogram(pred[name], bins=30, density=True)\n",
    "    width = (bins[1]-bins[0]).numpy()\n",
    "    ax[i].bar(bins[:-1].numpy(), h.numpy(), width=width, alpha=0.5, label=\"Posterior\")\n",
    "    \n",
    "    ax[i].plot(bins.numpy(), torch.exp(prior.log_prob(bins)).numpy(), \"r\", label=\"Prior\")\n",
    "    ax[i].set_title(name)\n",
    "    ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3ed7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopt-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
