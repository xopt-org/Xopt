{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Time dependent Bayesian Optimization\n",
    "\n",
    "In this example we demonstrate time dependent optimization. In this case we are not\n",
    "only interested in finding an optimum point in input space, but also maintain the\n",
    "ideal point over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values if testing\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import trange\n",
    "from xopt.generators.bayesian import TDUpperConfidenceBoundGenerator\n",
    "from xopt.vocs import VOCS\n",
    "from xopt.evaluator import Evaluator\n",
    "from xopt import Xopt\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "N_MC_SAMPLES = 1 if SMOKE_TEST else 128\n",
    "NUM_RESTARTS = 1 if SMOKE_TEST else 20\n",
    "N_STEPS = 1 if SMOKE_TEST else 250\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Time dependent test problem\n",
    "Optimization is carried out over a single variable `x`. The test function is a simple\n",
    " quadratic, with a minimum location that drifts and changes as a function of time `t`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Define test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T15:55:17.650035Z",
     "iopub.status.busy": "2024-09-13T15:55:17.649856Z",
     "iopub.status.idle": "2024-09-13T15:55:17.659060Z",
     "shell.execute_reply": "2024-09-13T15:55:17.658810Z"
    }
   },
   "outputs": [],
   "source": [
    "# location of time dependent minimum\n",
    "def k(t_):\n",
    "    return torch.where(\n",
    "        t_ < 50, 0.25 * torch.sin(t_ * 6 / 10.0) + 0.1e-2 * t_, -1.5e-2 * (t_ - 50.0)\n",
    "    )\n",
    "\n",
    "\n",
    "# define function in time and position space\n",
    "def g(x_, t_):\n",
    "    return (x_ - k(t_)) ** 2\n",
    "\n",
    "\n",
    "# create callable function for Xopt\n",
    "def f(inputs):\n",
    "    x_ = inputs[\"x\"]\n",
    "    current_time = time.time()\n",
    "    t_ = current_time - start_time\n",
    "    y_ = g(x_, torch.tensor(t_))\n",
    "\n",
    "    return {\"y\": float(y_), \"time\": float(current_time)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define Xopt objects including optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = {\"x\": [-1, 1]}\n",
    "objectives = {\"y\": \"MINIMIZE\"}\n",
    "\n",
    "vocs = VOCS(variables=variables, objectives=objectives)\n",
    "\n",
    "evaluator = Evaluator(function=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T15:55:17.679779Z",
     "iopub.status.busy": "2024-09-13T15:55:17.679658Z",
     "iopub.status.idle": "2024-09-13T15:55:40.915698Z",
     "shell.execute_reply": "2024-09-13T15:55:40.914547Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = TDUpperConfidenceBoundGenerator(\n",
    "    vocs=vocs,\n",
    "    beta=0.01,\n",
    "    added_time=0.1,\n",
    "    forgetting_time=10.0,\n",
    ")\n",
    "generator.n_monte_carlo_samples = N_MC_SAMPLES\n",
    "generator.numerical_optimizer.n_restarts = NUM_RESTARTS\n",
    "generator.max_travel_distances = [0.1]\n",
    "\n",
    "start_time = time.time()\n",
    "X = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)\n",
    "X.random_evaluate(2)\n",
    "\n",
    "for _ in trange(N_STEPS):\n",
    "    # note that in this example we can ignore warnings if computation\n",
    "    # time is greater than added time\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        X.step()\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Visualize GP model of objective function and plot trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X.data\n",
    "\n",
    "xbounds = generator.vocs.bounds\n",
    "tbounds = [data[\"time\"].min(), data[\"time\"].max()]\n",
    "\n",
    "model = X.generator.model\n",
    "n = 100\n",
    "t = torch.linspace(*tbounds, n, dtype=torch.double)\n",
    "x = torch.linspace(*xbounds.flatten(), n, dtype=torch.double)\n",
    "tt, xx = torch.meshgrid(t, x)\n",
    "pts = torch.hstack([ele.reshape(-1, 1) for ele in (tt, xx)]).double()\n",
    "\n",
    "tt, xx = tt.numpy(), xx.numpy()\n",
    "\n",
    "# NOTE: the model inputs are such that t is the last dimension\n",
    "gp_pts = torch.flip(pts, dims=[-1])\n",
    "\n",
    "gt_vals = g(gp_pts.T[0], gp_pts.T[1] - start_time)\n",
    "\n",
    "with torch.no_grad():\n",
    "    post = model.posterior(gp_pts)\n",
    "\n",
    "    mean = post.mean\n",
    "    std = torch.sqrt(post.variance)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"model mean\")\n",
    "    ax.set_xlabel(\"unix time\")\n",
    "    ax.set_ylabel(\"x\")\n",
    "    c = ax.pcolor(tt, xx, mean.reshape(n, n), rasterized=True)\n",
    "    ax.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(), \"oC1\", label=\"samples\")\n",
    "\n",
    "    ax.plot(t, k(t - start_time), \"C3--\", label=\"ideal path\", zorder=10)\n",
    "    ax.legend()\n",
    "    fig.colorbar(c)\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.set_title(\"model uncertainty\")\n",
    "    ax2.set_xlabel(\"unix time\")\n",
    "    ax2.set_ylabel(\"x\")\n",
    "    c = ax2.pcolor(tt, xx, std.reshape(n, n))\n",
    "    fig2.colorbar(c)\n",
    "\n",
    "    fig3, ax3 = plt.subplots()\n",
    "    ax3.set_title(\"ground truth value\")\n",
    "    ax3.set_xlabel(\"unix time\")\n",
    "    ax3.set_ylabel(\"x\")\n",
    "    c = ax3.pcolor(tt, xx, gt_vals.reshape(n, n))\n",
    "    fig3.colorbar(c)\n",
    "\n",
    "    ax2.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(), \"oC1\")\n",
    "    ax3.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(), \"oC1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## plot the acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T15:55:41.794609Z",
     "iopub.status.busy": "2024-09-13T15:55:41.794517Z",
     "iopub.status.idle": "2024-09-13T15:55:42.112062Z",
     "shell.execute_reply": "2024-09-13T15:55:42.111804Z"
    }
   },
   "outputs": [],
   "source": [
    "# note that target time is only updated during the generate call\n",
    "target_time = X.generator.target_prediction_time\n",
    "print(target_time - start_time)\n",
    "my_acq_func = X.generator.get_acquisition(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    acq_pts = x.unsqueeze(-1).unsqueeze(-1)\n",
    "    full_acq = my_acq_func.acq_func(gp_pts.unsqueeze(1))\n",
    "    fixed_acq = my_acq_func(acq_pts)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    c = ax.pcolor(tt, xx, full_acq.reshape(n, n))\n",
    "    ax.set_xlabel(\"unix time\")\n",
    "    ax.set_ylabel(\"x\")\n",
    "    ax.set_title(\"acquisition function\")\n",
    "    fig.colorbar(c)\n",
    "\n",
    "    fi2, ax2 = plt.subplots()\n",
    "    ax2.plot(x.flatten(), fixed_acq.flatten())\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"acquisition function\")\n",
    "    ax2.set_title(\"acquisition function at last time step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Run Time Dependent BO with Model Caching\n",
    "Instead of retraining the GP model hyperparameters at every step, we can instead hold\n",
    "on to previously determined model parameters by setting\n",
    "`use_catched_hyperparameters=True` in the model constructor. This reduces the time\n",
    "needed to make decisions, leading to faster feedback when addressing time-critical\n",
    "optimization tasks. However,  this can come at the cost of model accuracy when the\n",
    "target function changes behavior (change in lengthscale for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TDUpperConfidenceBoundGenerator(\n",
    "    vocs=vocs,\n",
    "    beta=0.01,\n",
    "    added_time=0.1,\n",
    "    forgetting_time=20.0,\n",
    ")\n",
    "generator.n_monte_carlo_samples = N_MC_SAMPLES\n",
    "generator.numerical_optimizer.n_restarts = NUM_RESTARTS\n",
    "generator.max_travel_distances = [0.1]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "X = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)\n",
    "X.random_evaluate(2)\n",
    "\n",
    "for i in trange(N_STEPS):\n",
    "    # note that in this example we can ignore warnings if computation time is greater\n",
    "    # than added time\n",
    "    if i == 50:\n",
    "        X.generator.gp_constructor.use_cached_hyperparameters = True\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        X.step()\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot total computation time\n",
    "ax = X.generator.computation_time.sum(axis=1).plot()\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"total BO computation time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X.data\n",
    "\n",
    "xbounds = generator.vocs.bounds\n",
    "tbounds = [data[\"time\"].min(), data[\"time\"].max()]\n",
    "\n",
    "model = X.generator.model\n",
    "n = 100\n",
    "t = torch.linspace(*tbounds, n, dtype=torch.double)\n",
    "x = torch.linspace(*xbounds.flatten(), n, dtype=torch.double)\n",
    "tt, xx = torch.meshgrid(t, x)\n",
    "pts = torch.hstack([ele.reshape(-1, 1) for ele in (tt, xx)]).double()\n",
    "\n",
    "tt, xx = tt.numpy(), xx.numpy()\n",
    "\n",
    "# NOTE: the model inputs are such that t is the last dimension\n",
    "gp_pts = torch.flip(pts, dims=[-1])\n",
    "\n",
    "gt_vals = g(gp_pts.T[0], gp_pts.T[1] - start_time)\n",
    "\n",
    "with torch.no_grad():\n",
    "    post = model.posterior(gp_pts)\n",
    "\n",
    "    mean = post.mean\n",
    "    std = torch.sqrt(post.variance)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"model mean\")\n",
    "    ax.set_xlabel(\"unix time\")\n",
    "    ax.set_ylabel(\"x\")\n",
    "    c = ax.pcolor(tt, xx, mean.reshape(n, n))\n",
    "    ax.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(), \"oC1\", label=\"samples\")\n",
    "\n",
    "    ax.plot(t, k(t - start_time), \"C3--\", label=\"ideal path\", zorder=10)\n",
    "    ax.legend()\n",
    "    fig.colorbar(c)\n",
    "\n",
    "    fig2, ax2 = plt.subplots()\n",
    "    ax2.set_title(\"model uncertainty\")\n",
    "    ax2.set_xlabel(\"unix time\")\n",
    "    ax2.set_ylabel(\"x\")\n",
    "    c = ax2.pcolor(tt, xx, std.reshape(n, n))\n",
    "    fig2.colorbar(c)\n",
    "\n",
    "    fig3, ax3 = plt.subplots()\n",
    "    ax3.set_title(\"ground truth value\")\n",
    "    ax3.set_xlabel(\"unix time\")\n",
    "    ax3.set_ylabel(\"x\")\n",
    "    c = ax3.pcolor(tt, xx, gt_vals.reshape(n, n))\n",
    "    fig3.colorbar(c)\n",
    "\n",
    "    ax2.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(), \"oC1\")\n",
    "    ax3.plot(data[\"time\"].to_numpy(), data[\"x\"].to_numpy(), \"oC1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
