{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Constrained Bayesian Optimization with EI and UCB\n",
    "In this tutorial we demonstrate the use of Xopt to perform Bayesian Optimization on a simple test problem subject to a single constraint. We will compare two acquisition functions:\n",
    "1. **Expected Improvement (EI)** - balances exploitation and exploration by targeting areas with high probability of improvement\n",
    "2. **Upper Confidence Bound (UCB)** - uses an explicit $\\beta$ parameter to balance exploration and exploitation. **However, it requires special consideration when using with constraints**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Define the test problem\n",
    "Here we define a simple optimization problem, where we attempt to minimize the sin\n",
    "function in the domian [0,2*pi], subject to a cos constraining function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:55:57.751261500Z",
     "start_time": "2025-01-07T20:55:53.793271Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from xopt.evaluator import Evaluator\n",
    "from xopt.generators.bayesian import (\n",
    "    ExpectedImprovementGenerator,\n",
    "    UpperConfidenceBoundGenerator,\n",
    ")\n",
    "from xopt import Xopt\n",
    "from xopt.vocs import VOCS, select_best\n",
    "\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore all warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# define fixed seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# define variables, function objective and constraining function\n",
    "vocs = VOCS(\n",
    "    variables={\"x\": [0, 2 * math.pi]},\n",
    "    objectives={\"f\": \"MINIMIZE\"},\n",
    "    constraints={\"c\": [\"LESS_THAN\", 0]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:55:57.766139300Z",
     "start_time": "2025-01-07T20:55:57.738794400Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# define a test function to optimize\n",
    "def test_function(input_dict):\n",
    "    return {\"f\": np.sin(input_dict[\"x\"]), \"c\": np.cos(input_dict[\"x\"] + 0.5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Constrained Bayesian Optimization with Expected Improvement (EI)\n",
    "Create the evaluator to evaluate our test function and create a generator that uses\n",
    "the Expected Improvement acquisition function to perform Bayesian Optimization. Note that because we are optimizing a problem with no noise we set `use_low_noise_prior=True` in the GP model constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:55:57.766682400Z",
     "start_time": "2025-01-07T20:55:57.751261500Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator(function=test_function)\n",
    "generator_ei = ExpectedImprovementGenerator(vocs=vocs)\n",
    "generator_ei.gp_constructor.use_low_noise_prior = True\n",
    "X_ei = Xopt(evaluator=evaluator, generator=generator_ei)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Generate and evaluate initial points for EI\n",
    "To begin optimization, we must generate some random initial data points. The first call\n",
    "to `X.step()` will generate and evaluate a number of randomly points specified by the\n",
    " generator. Note that if we add data to xopt before calling `X.step()` by assigning\n",
    " the data to `X.data`, calls to `X.step()` will ignore the random generation and\n",
    " proceed to generating points via Bayesian optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:55:57.767710800Z",
     "start_time": "2025-01-07T20:55:57.766139300Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# call X.random_evaluate(n_samples) to generate + evaluate initial points\n",
    "X_ei.random_evaluate(n_samples=3)\n",
    "\n",
    "# inspect the gathered data\n",
    "print(\"Initial data for EI optimization:\")\n",
    "print(X_ei.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Do Bayesian optimization steps with EI\n",
    "To perform optimization we simply call `X.step()` in a loop. This allows us to do\n",
    "intermediate tasks in between optimization steps, such as examining the model and\n",
    "acquisition function at each step (as we demonstrate here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T20:57:47.398979200Z",
     "start_time": "2025-01-07T20:57:37.742437900Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n_steps = 5\n",
    "\n",
    "# test points for plotting\n",
    "test_x = np.linspace(*X_ei.vocs.bounds[0], 50)\n",
    "\n",
    "print(\"=== Expected Improvement Optimization ===\")\n",
    "for i in range(n_steps):\n",
    "    print(f\"EI Step {i + 1}\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # train model and visualize\n",
    "    model = X_ei.generator.train_model()\n",
    "    fig, ax = X_ei.generator.visualize_model(n_grid=100)\n",
    "    fig.suptitle(f\"Expected Improvement - Step {i + 1}\")\n",
    "\n",
    "    # add ground truth functions to plots\n",
    "    out = test_function({\"x\": test_x})\n",
    "    ax[0, 0].plot(test_x, out[\"f\"], \"C0-.\", label=\"True objective\", linewidth=2)\n",
    "    ax[1, 0].plot(test_x, out[\"c\"], \"C2-.\", label=\"True constraint\", linewidth=2)\n",
    "    ax[0, 0].legend()\n",
    "    ax[1, 0].legend()\n",
    "\n",
    "    plt.show()\n",
    "    print(f\"Time: {time.perf_counter() - start:.3f}s\")\n",
    "\n",
    "    # do the optimization step\n",
    "    X_ei.step()\n",
    "    print(f\"Current best: f = {select_best(X_ei.vocs, X_ei.data)[1].item():.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# access the collected data from EI optimization\n",
    "print(\"Final EI optimization results:\")\n",
    "print(X_ei.data)\n",
    "print(f\"EI Best valid solution: {select_best(X_ei.vocs, X_ei.data)[1].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained Bayesian Optimization with Upper Confidence Bound (UCB)\n",
    "\n",
    "The Upper Confidence Bound acquisition function allows a user to explicitly specify the balance between exploration and exploitation. However, for **constrained optimization**, there is an important technical requirement:\n",
    "\n",
    "1. **Constraint handling requires positive acquisition values**: When constraints are present, the acquisition function is weighted by the probability of feasibility, **this will only work with strictly positive acquisition function values!**.\n",
    "3. **The `shift` parameter ensures positivity**: Adding a positive shift ensures the UCB acquisition function is strictly positive, which is required for proper constraint weighting. Note that this addition will not change the location of the acquisition function maximum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UCB generator with shift parameter for constrained optimization\n",
    "# The shift parameter ensures the acquisition function is strictly positive\n",
    "# This is required because constrained optimization weights the acquisition\n",
    "# function by the probability of feasibility: α_constrained = α_unconstrained × P(feasible)\n",
    "generator_ucb = UpperConfidenceBoundGenerator(vocs=vocs, shift=2.0)\n",
    "generator_ucb.gp_constructor.use_low_noise_prior = True\n",
    "\n",
    "# Create new Xopt object for UCB\n",
    "X_ucb = Xopt(evaluator=evaluator, generator=generator_ucb, vocs=vocs)\n",
    "\n",
    "print(\"UCB Generator configuration:\")\n",
    "print(f\"Shift parameter: {generator_ucb.shift}\")\n",
    "print(\"This shift ensures UCB values are strictly positive for constraint weighting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate initial points for UCB optimization\n",
    "X_ucb.random_evaluate(n_samples=3)\n",
    "\n",
    "print(\"Initial data for UCB optimization:\")\n",
    "print(X_ucb.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Upper Confidence Bound Optimization ===\")\n",
    "for i in range(n_steps):\n",
    "    print(f\"UCB Step {i + 1}\")\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    # train model and visualize\n",
    "    model = X_ucb.generator.train_model()\n",
    "    fig, ax = X_ucb.generator.visualize_model(n_grid=100)\n",
    "    fig.suptitle(f\"Upper Confidence Bound (shift={generator_ucb.shift}) - Step {i + 1}\")\n",
    "\n",
    "    # add ground truth functions to plots\n",
    "    out = test_function({\"x\": test_x})\n",
    "    ax[0, 0].plot(test_x, out[\"f\"], \"C0-.\", label=\"True objective\", linewidth=2)\n",
    "    ax[1, 0].plot(test_x, out[\"c\"], \"C2-.\", label=\"True constraint\", linewidth=2)\n",
    "    ax[0, 0].legend()\n",
    "    ax[1, 0].legend()\n",
    "\n",
    "    plt.show()\n",
    "    print(f\"Time: {time.perf_counter() - start:.3f}s\")\n",
    "\n",
    "    # do the optimization step\n",
    "    X_ucb.step()\n",
    "    print(f\"Current best: f = {select_best(X_ucb.vocs, X_ucb.data)[1].item():.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the collected data from UCB optimization\n",
    "print(\"Final UCB optimization results:\")\n",
    "print(X_ucb.data)\n",
    "print(f\"UCB Best valid solution: {select_best(X_ucb.vocs, X_ucb.data)[1].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "**Expected Improvement (EI):**\n",
    "- Natural balance between exploration and exploitation\n",
    "- Works well out-of-the-box for both maximization and minimization\n",
    "- Always positive, making it naturally compatible with constraints\n",
    "- Tends to be more exploitative near the current best\n",
    "\n",
    "**Upper Confidence Bound (UCB) for Constrained Optimization:**\n",
    "- **Requires `shift` parameter for constraints**: UCB can be negative, but constrained optimization requires positive acquisition values\n",
    "- **Technical requirement**: `α_constrained(x) = α_unconstrained(x) × P(feasible|x)` needs `α_unconstrained(x) > 0`\n",
    "- **Shift > 0**: Ensures UCB acquisition function is strictly positive\n",
    "\n",
    "**With Constraints:**\n",
    "- Both acquisition functions handle constraints by incorporating constraint predictions\n",
    "- The visualization shows both the objective model and constraint model\n",
    "- Acquisition function values are weighted by probability of feasibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopt-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
