{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Trust Region Controllers in Xopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trust Region Bayesian Optimization (TuRBO) is an advanced optimization algorithm designed for solving high-dimensional black-box optimization problems. It combines the strengths of Bayesian Optimization (BO) with trust region methods to improve scalability and efficiency.\n",
    "\n",
    "### Key Features:\n",
    "1. **Trust Regions**:\n",
    "    - TuRBO uses local trust regions to focus the search in promising areas of the parameter space.\n",
    "    - Each trust region is a bounded subspace where the optimization is performed, and its size is dynamically adjusted based on the success of the optimization.\n",
    "\n",
    "2. **Bayesian Surrogate Model**:\n",
    "    - A Gaussian Process (GP) or other surrogate models are used to approximate the objective function.\n",
    "    - This surrogate model is used to predict the objective function and guide the search as well as define the size of the trust region.\n",
    "\n",
    "4. **Adaptivity**:\n",
    "    - The algorithm adapts the size of the trust region based on the success or failure of the optimization steps. If the optimization within a trust region is successful, the region expands; otherwise, it shrinks.\n",
    "\n",
    "### Advantages:\n",
    "- Scales better to high-dimensional problems compared to standard Bayesian Optimization.\n",
    "- Efficiently balances exploration and exploitation within trust regions.\n",
    "\n",
    "### Disadvantages:\n",
    "- Severely restricts exploration of the parameter space potentially leading to convergence to local minima, thus making it sensitive to initial sampling points.\n",
    "- Introduces additional algorithm hyperparameters which can cause issues.  \n",
    "- May struggle with noisy objective functions or discontinuous landscapes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a TuRBO Controller\n",
    "Currently, Xopt supports 3 different TuRBO controller types, the most basic of which is the `OptimizeTurboController`. To create this controller we need to define our optimization problem and some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xopt import VOCS\n",
    "from xopt.vocs import random_inputs\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# create evaluation function\n",
    "def sphere_function(inputs):\n",
    "    \"\"\"\n",
    "    2D Sphere objective function.\n",
    "    Compatible with Xopt.\n",
    "    \"\"\"\n",
    "    x, y = inputs[\"x\"], inputs[\"y\"]\n",
    "    return {\"f\": np.sum(np.square(np.stack([x, y], axis=-1)), axis=-1)}\n",
    "\n",
    "\n",
    "# create a VOCS object\n",
    "vocs = VOCS(\n",
    "    variables={\"x\": [-5, 5], \"y\": [-5, 5]},\n",
    "    objectives={\"f\": \"MINIMIZE\"},\n",
    ")\n",
    "\n",
    "# random sample 10 points\n",
    "x0 = random_inputs(vocs, 10)\n",
    "\n",
    "# evaluate the function at the random points\n",
    "f = []\n",
    "for i in range(len(x0)):\n",
    "    f += [sphere_function(x0[i]) | x0[i]]\n",
    "\n",
    "# print the results\n",
    "data = pd.DataFrame(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ExpectedImprovementGenerator and train the GP model\n",
    "Here we create the ExpectedImprovementGenerator, add data to the generator, and train the model from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian import ExpectedImprovementGenerator\n",
    "\n",
    "generator = ExpectedImprovementGenerator(vocs=vocs)  # create the generator\n",
    "generator.gp_constructor.use_low_noise_prior = True\n",
    "generator.add_data(data)  # add the data to the generator\n",
    "generator.train_model()  # train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Optimize Turbo Controller\n",
    "Here we create the controller and view the different parameters with their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.turbo import OptimizeTurboController\n",
    "\n",
    "turbo_controller = OptimizeTurboController(vocs=vocs)\n",
    "\n",
    "print(turbo_controller.__doc__)\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# examine the attributes of the controller\n",
    "for field_name, field in turbo_controller.model_fields.items():\n",
    "    print(f\"Field: {field_name}\")\n",
    "    print(f\"  Description: {field.description}\")\n",
    "    print(f\"  Type: {field.annotation}\")\n",
    "    print(f\"  Default: {field.default}\")\n",
    "    print(f\"  Value: {getattr(turbo_controller, field_name)}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Trust Region\n",
    "Here we get the current trust region \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_region = turbo_controller.get_trust_region(\n",
    "    generator=generator\n",
    ")  # get the trust region of the model\n",
    "print(f\"Trust Region: {trust_region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the trust region\n",
    "Add another data point to the generator (as if we performed one optimization step) and update the turbo controller. We will add a point that improves over the best function value measured so far so this measurement will count as a success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new point to the generator\n",
    "new_point = pd.DataFrame({\"x\": [0.0], \"y\": [0.0], \"f\": [0.0]})\n",
    "generator.add_data(new_point)  # add the new point to the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.train_model()  # train the model again\n",
    "\n",
    "# update the TuRBO controller\n",
    "turbo_controller.update_state(generator)\n",
    "\n",
    "# get the new trust region\n",
    "trust_region = turbo_controller.get_trust_region(\n",
    "    generator=generator\n",
    ")  # get the trust region of the model\n",
    "print(f\"New Trust Region: {trust_region}\")\n",
    "\n",
    "# get the number of successes and failures\n",
    "print(f\"Number of successes: {turbo_controller.success_counter}\")\n",
    "print(f\"Number of failures: {turbo_controller.failure_counter}\")\n",
    "\n",
    "# get the base length scale of the trust region\n",
    "print(f\"Base length scale: {turbo_controller.length}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
